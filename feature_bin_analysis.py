import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict
import warnings
warnings.filterwarnings('ignore')

# è¨­ç½®ä¸­æ–‡å­—é«”
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class FeatureBinAnalyzer:
    def __init__(self, binned_data_path, original_data_path):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        """
        self.binned_df = pd.read_csv(binned_data_path)
        self.original_df = pd.read_csv(original_data_path)
        
        # ç²å–æ‰€æœ‰åˆ†ç®±ç‰¹å¾µåç¨±
        self.binned_features = [col for col in self.binned_df.columns if col.endswith('_binned')]
        
        # è¨ˆç®—æœªä¾†æ”¶ç›Šç‡
        self._calculate_future_returns()
        
    def _calculate_future_returns(self):
        """
        è¨ˆç®—æœªä¾†12ç­†çª—å£å…§çš„é«˜é»å’Œä½é»
        """
        # æœªä¾†12ç­†çª—å£å…§çš„æœ€é«˜åƒ¹
        self.binned_df['future_high_12'] = self.binned_df['high'].shift(-12).rolling(window=12).max()
        # æœªä¾†12ç­†çª—å£å…§çš„æœ€ä½åƒ¹
        self.binned_df['future_low_12'] = self.binned_df['low'].shift(-12).rolling(window=12).min()
        
        # è¨ˆç®—ç›¸å°æ–¼ç•¶å‰closeçš„è®ŠåŒ–ç™¾åˆ†æ¯”
        self.binned_df['future_high_pct'] = (self.binned_df['future_high_12'] - self.binned_df['close']) / self.binned_df['close']
        self.binned_df['future_low_pct'] = (self.binned_df['future_low_12'] - self.binned_df['close']) / self.binned_df['close']
        
        # æœªä¾†è¶¨å‹¢æ–¹å‘ (é«˜é»ä¸Šæ¼²=1, ä½é»ä¸‹è·Œ=0)
        self.binned_df['future_high_direction'] = (self.binned_df['future_high_pct'] > 0).astype(int)
        self.binned_df['future_low_direction'] = (self.binned_df['future_low_pct'] < 0).astype(int)
        
    def analyze_single_feature(self, feature_name, targets=['high', 'low']):
        """
        åˆ†æå–®å€‹ç‰¹å¾µèˆ‡æœªä¾†çª—å£é«˜é»ã€ä½é»çš„é—œä¿‚
        """
        if feature_name not in self.binned_features:
            print(f"ç‰¹å¾µ {feature_name} ä¸åœ¨åˆ†ç®±ç‰¹å¾µåˆ—è¡¨ä¸­")
            return None
            
        results = {}
        
        for target in targets:
            if target == 'high':
                pct_col = 'future_high_pct'
                direction_col = 'future_high_direction'
                label = 'é«˜é»'
            else:
                pct_col = 'future_low_pct'
                direction_col = 'future_low_direction'
                label = 'ä½é»'
            
            # æŒ‰ç®±å­åˆ†çµ„çµ±è¨ˆ
            group_stats = self.binned_df.groupby(feature_name).agg({
                pct_col: ['count', 'mean', 'std'],
                direction_col: ['sum', 'mean']
            }).round(4)
            
            # é‡æ–°å‘½ååˆ—
            group_stats.columns = [f'{label}_æ¨£æœ¬æ•¸', f'{label}_å¹³å‡è®ŠåŒ–%', f'{label}_è®ŠåŒ–æ¨™æº–å·®', 
                                 f'{label}_ä¸Šæ¼²æ¬¡æ•¸', f'{label}_ä¸Šæ¼²æ©Ÿç‡']
            
            results[f'{label}é æ¸¬'] = group_stats
            
        return results
    
    def analyze_all_features(self, targets=['high', 'low'], top_n=10):
        """
        åˆ†ææ‰€æœ‰ç‰¹å¾µï¼Œæ‰¾å‡ºèˆ‡æœªä¾†çª—å£é«˜é»ã€ä½é»é—œä¿‚æœ€å¼·çš„ç‰¹å¾µ
        """
        feature_scores = {}
        
        for feature in self.binned_features:
            scores = []
            
            for target in targets:
                if target == 'high':
                    direction_col = 'future_high_direction'
                else:
                    direction_col = 'future_low_direction'
                
                # è¨ˆç®—ä¸åŒç®±å­é–“ä¸Šæ¼²æ©Ÿç‡çš„å·®ç•°ï¼ˆä½œç‚ºé æ¸¬èƒ½åŠ›æŒ‡æ¨™ï¼‰
                bin_probs = self.binned_df.groupby(feature)[direction_col].mean()
                
                if len(bin_probs) > 1:
                    # ä½¿ç”¨æ¨™æº–å·®è¡¡é‡ç®±å­é–“å·®ç•°
                    prob_std = bin_probs.std()
                    scores.append(prob_std)
                else:
                    scores.append(0)
            
            # å–å¹³å‡ä½œç‚ºè©²ç‰¹å¾µçš„ç¸½é«”å¾—åˆ†
            feature_scores[feature] = np.mean(scores)
        
        # æ’åºä¸¦å–å‰Nå€‹
        sorted_features = sorted(feature_scores.items(), key=lambda x: x[1], reverse=True)
        
        print("=" * 60)
        print(f"é æ¸¬èƒ½åŠ›æ’åå‰ {top_n} çš„ç‰¹å¾µ:")
        print("=" * 60)
        
        for i, (feature, score) in enumerate(sorted_features[:top_n], 1):
            print(f"{i:2d}. {feature:<25} é æ¸¬å¾—åˆ†: {score:.4f}")
            
        return sorted_features[:top_n]
    
    def plot_feature_analysis(self, feature_name, targets=['high', 'low']):
        """
        ç¹ªè£½ç‰¹å¾µåˆ†æåœ–è¡¨
        """
        if feature_name not in self.binned_features:
            print(f"ç‰¹å¾µ {feature_name} ä¸åœ¨åˆ†ç®±ç‰¹å¾µåˆ—è¡¨ä¸­")
            return
            
        fig, axes = plt.subplots(2, len(targets), figsize=(5*len(targets), 10))
        if len(targets) == 1:
            axes = axes.reshape(2, 1)
            
        for i, target in enumerate(targets):
            if target == 'high':
                pct_col = 'future_high_pct'
                direction_col = 'future_high_direction'
                label = 'é«˜é»'
                color_return = 'red'
                color_prob = 'darkred'
            else:
                pct_col = 'future_low_pct'
                direction_col = 'future_low_direction'
                label = 'ä½é»'
                color_return = 'blue'
                color_prob = 'darkblue'
            
            # ä¸Šæ–¹åœ–ï¼šå¹³å‡è®ŠåŒ–ç™¾åˆ†æ¯”
            data_pct = self.binned_df.groupby(feature_name)[pct_col].mean()
            axes[0, i].bar(data_pct.index, data_pct.values, alpha=0.7, color=color_return)
            axes[0, i].set_title(f'{feature_name}\næœªä¾†12ç­†{label}å¹³å‡è®ŠåŒ–%')
            axes[0, i].set_xlabel('ç®±å­')
            axes[0, i].set_ylabel('å¹³å‡è®ŠåŒ–%')
            axes[0, i].axhline(y=0, color='black', linestyle='--', alpha=0.5)
            
            # ä¸‹æ–¹åœ–ï¼šæ–¹å‘æ©Ÿç‡
            data_prob = self.binned_df.groupby(feature_name)[direction_col].mean()
            axes[1, i].bar(data_prob.index, data_prob.values, alpha=0.7, color=color_prob)
            axes[1, i].set_title(f'æœªä¾†12ç­†{label}æ–¹å‘æ©Ÿç‡')
            axes[1, i].set_xlabel('ç®±å­')
            axes[1, i].set_ylabel('æ–¹å‘æ©Ÿç‡')
            axes[1, i].axhline(y=0.5, color='black', linestyle='--', alpha=0.5)
            axes[1, i].set_ylim(0, 1)
            
        plt.tight_layout()
        plt.show()
        
    def generate_comprehensive_report(self, top_features=5):
        """
        ç”Ÿæˆç¶œåˆåˆ†æå ±å‘Š
        """
        print("=" * 80)
        print("ç‰¹å¾µç®±å­èˆ‡æœªä¾†çª—å£é«˜é»ã€ä½é»é—œä¿‚åˆ†æå ±å‘Š")
        print("=" * 80)
        
        # 1. æ•´é«”çµ±è¨ˆ
        print(f"\nğŸ“Š æ•¸æ“šæ¦‚è¦½:")
        print(f"   ç¸½æ¨£æœ¬æ•¸: {len(self.binned_df)}")
        print(f"   åˆ†ç®±ç‰¹å¾µæ•¸: {len(self.binned_features)}")
        print(f"   åˆ†ææœŸé–“: {self.binned_df['Date'].min()} è‡³ {self.binned_df['Date'].max()}")
        
        # 2. æ‰¾å‡ºé æ¸¬èƒ½åŠ›æœ€å¼·çš„ç‰¹å¾µ
        top_predictive_features = self.analyze_all_features(top_n=top_features)
        
        print(f"\nğŸ“ˆ è©³ç´°åˆ†æå‰ {top_features} å€‹ç‰¹å¾µ:")
        print("=" * 80)
        
        # 3. è©³ç´°åˆ†ææ¯å€‹é ‚ç´šç‰¹å¾µ
        for i, (feature_name, score) in enumerate(top_predictive_features, 1):
            print(f"\n{i}. {feature_name} (é æ¸¬å¾—åˆ†: {score:.4f})")
            print("-" * 60)
            
            # åˆ†æçµæœ
            results = self.analyze_single_feature(feature_name)
            
            if results:
                for target, stats in results.items():
                    print(f"\n  {target}é æ¸¬çµæœ:")
                    print(stats.to_string())
        
        return top_predictive_features
    
    def generate_json_report(self, top_features=8):
        """
        ç”ŸæˆJSONæ ¼å¼çš„åˆ†æå ±å‘Š
        """
        import json
        
        # ç²å–å‰Nå€‹ç‰¹å¾µ
        top_predictive_features = self.analyze_all_features(top_n=top_features)
        
        report = {
            "analysis_type": "ç‰¹å¾µç®±å­èˆ‡æœªä¾†çª—å£é«˜é»ã€ä½é»é—œä¿‚åˆ†æ",
            "data_overview": {
                "total_samples": len(self.binned_df),
                "binned_features_count": len(self.binned_features),
                "analysis_period": {
                    "start": str(self.binned_df['Date'].min()),
                    "end": str(self.binned_df['Date'].max())
                }
            },
            "top_features": []
        }
        
        for i, (feature_name, score) in enumerate(top_predictive_features, 1):
            feature_data = {
                "rank": i,
                "feature_name": feature_name,
                "prediction_score": round(score, 4),
                "high_point_analysis": {},
                "low_point_analysis": {}
            }
            
            # åˆ†æçµæœ
            results = self.analyze_single_feature(feature_name)
            
            if results:
                # é«˜é»åˆ†æ
                if 'é«˜é»é æ¸¬' in results:
                    high_stats = results['é«˜é»é æ¸¬']
                    for bin_value in high_stats.index:
                        feature_data["high_point_analysis"][str(bin_value)] = {
                            "sample_count": int(high_stats.loc[bin_value, 'é«˜é»_æ¨£æœ¬æ•¸']),
                            "avg_change_pct": round(float(high_stats.loc[bin_value, 'é«˜é»_å¹³å‡è®ŠåŒ–%']), 4),
                            "change_std": round(float(high_stats.loc[bin_value, 'é«˜é»_è®ŠåŒ–æ¨™æº–å·®']), 4),
                            "up_count": int(high_stats.loc[bin_value, 'é«˜é»_ä¸Šæ¼²æ¬¡æ•¸']),
                            "up_probability": round(float(high_stats.loc[bin_value, 'é«˜é»_ä¸Šæ¼²æ©Ÿç‡']), 4)
                        }
                
                # ä½é»åˆ†æ
                if 'ä½é»é æ¸¬' in results:
                    low_stats = results['ä½é»é æ¸¬']
                    for bin_value in low_stats.index:
                        feature_data["low_point_analysis"][str(bin_value)] = {
                            "sample_count": int(low_stats.loc[bin_value, 'ä½é»_æ¨£æœ¬æ•¸']),
                            "avg_change_pct": round(float(low_stats.loc[bin_value, 'ä½é»_å¹³å‡è®ŠåŒ–%']), 4),
                            "change_std": round(float(low_stats.loc[bin_value, 'ä½é»_è®ŠåŒ–æ¨™æº–å·®']), 4),
                            "up_count": int(low_stats.loc[bin_value, 'ä½é»_ä¸Šæ¼²æ¬¡æ•¸']),
                            "up_probability": round(float(low_stats.loc[bin_value, 'ä½é»_ä¸Šæ¼²æ©Ÿç‡']), 4)
                        }
            
            report["top_features"].append(feature_data)
        
        return report

# å‰µå»ºåˆ†æå™¨å¯¦ä¾‹
analyzer = FeatureBinAnalyzer('data/binned_features.csv', 'data/cleaned_features.csv')

# ç”Ÿæˆç¶œåˆå ±å‘Š
print("æ­£åœ¨ç”Ÿæˆç‰¹å¾µç®±å­èˆ‡æœªä¾†çª—å£é«˜é»ã€ä½é»é—œä¿‚åˆ†æå ±å‘Š...")
top_features = analyzer.generate_comprehensive_report(top_features=8)

# ç”ŸæˆJSONå ±å‘Š
print("\næ­£åœ¨ç”ŸæˆJSONæ ¼å¼å ±å‘Š...")
import json
json_report = analyzer.generate_json_report(top_features=8)

# ä¿å­˜åˆ°æ–‡ä»¶
with open('data/feature_analysis_report.json', 'w', encoding='utf-8') as f:
    json.dump(json_report, f, ensure_ascii=False, indent=2)

print("JSONå ±å‘Šå·²ä¿å­˜åˆ°: feature_analysis_report.json")
